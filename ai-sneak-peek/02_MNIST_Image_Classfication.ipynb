{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"colab":{"name":"MNIST Image Classification.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"P6C3Z-lpCvR2"},"source":["# Image Classification with Deep Neural Networks\r\n","\r\n","In our regression example you have seen how to train a neural network with fast.ai.\r\n","\r\n","We will do the same here, but this time we will classify images, something Deep Neural Networks are often doing much better than any 'traditional' machine learning algorithms.\r\n","\r\n","We will still start slow and use the MNIST dataset before going into using larger more complex and colorful images."]},{"cell_type":"markdown","metadata":{"id":"9Dyt7cGZBmiN"},"source":["Run the code below to install and import all necessary packages."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Da5I2L-k8WDg","executionInfo":{"status":"ok","timestamp":1611225093820,"user_tz":-60,"elapsed":12386,"user":{"displayName":"Merlin Schäfer","photoUrl":"https://lh5.googleusercontent.com/-qjKM6-nJ5vA/AAAAAAAAAAI/AAAAAAAAAEM/6QXLPvQFe1s/s64/photo.jpg","userId":"00421792487393303898"}},"outputId":"2dcc368c-fd1c-4bbe-e342-b835a78eb278"},"source":["!pip install -Uqq fastbook\n","!pip install ipyplot  \n","import ipyplot\n","from fastai.vision.all import *\n","import matplotlib.pyplot as plt\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gg5y7gFLBujp"},"source":["## Getting our data\r\n","Here on colabs your directory will be newly set up every time you open the notebook. If you wish to permanently store inputs and outputs you can connect your colabs workspace to Google Drive.\r\n","\r\n","For now we don't need any permanent storage so we will just use the current working directory.\r\n","\r\n","\r\n","Using the fast.ai `untar_data() ` function we download and unzip the MNIST dataset for our classification task."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"HbyYANDa8WDn","executionInfo":{"status":"ok","timestamp":1611225116735,"user_tz":-60,"elapsed":35277,"user":{"displayName":"Merlin Schäfer","photoUrl":"https://lh5.googleusercontent.com/-qjKM6-nJ5vA/AAAAAAAAAAI/AAAAAAAAAEM/6QXLPvQFe1s/s64/photo.jpg","userId":"00421792487393303898"}},"outputId":"7f03670e-d831-4a35-8b70-581ec0b8e938"},"source":["path = untar_data(URLs.MNIST) #this will download and extract the dataset , it may take a while (163 MB)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1__nSLMS8WDo"},"source":["Loading the data may take a second.In the meantime you can read about the dataset [here](http://yann.lecun.com/exdb/mnist/)"]},{"cell_type":"markdown","metadata":{"id":"HVEdtd2sCiUC"},"source":["Once the dataset it loaded we make it's directory our base path for easier access.\r\n","You can check any subfolder of the path object with `.ls()`."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k3LOrvIp8WDo","executionInfo":{"status":"ok","timestamp":1611225116736,"user_tz":-60,"elapsed":35271,"user":{"displayName":"Merlin Schäfer","photoUrl":"https://lh5.googleusercontent.com/-qjKM6-nJ5vA/AAAAAAAAAAI/AAAAAAAAAEM/6QXLPvQFe1s/s64/photo.jpg","userId":"00421792487393303898"}},"outputId":"f91f0a2d-3c74-4fa1-a521-c14d899adbf7"},"source":["Path.BASE_PATH = path\n","\n","path.ls()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nvJbo-2VCyC0"},"source":["#### NOW YOU \r\n","Use the `.ls()` method to find out which subfolder are in the 'training' folder."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f_4_RJ0W8WDp","executionInfo":{"status":"ok","timestamp":1611225127335,"user_tz":-60,"elapsed":948,"user":{"displayName":"Merlin Schäfer","photoUrl":"https://lh5.googleusercontent.com/-qjKM6-nJ5vA/AAAAAAAAAAI/AAAAAAAAAEM/6QXLPvQFe1s/s64/photo.jpg","userId":"00421792487393303898"}},"outputId":"95108e90-2f09-4312-da44-04994067764d"},"source":["##YOUR CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vCb-aJWt8WDp"},"source":["You can see that within the training folder we have a folder for each digit.\n","The folder name corresponds to the label of the images. This is something we can use when preparing our data for training.\n","\n","Lets access one folder and open one image to see what they look like."]},{"cell_type":"markdown","metadata":{"id":"F9JYwBDhDBit"},"source":["#### NOW YOU\r\n","create a 'sevens' object that contains the paths to all subfolders of the '7' folder in the 'training' folder."]},{"cell_type":"code","metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"LMp946-M8WDp","executionInfo":{"status":"ok","timestamp":1611225129361,"user_tz":-60,"elapsed":1160,"user":{"displayName":"Merlin Schäfer","photoUrl":"https://lh5.googleusercontent.com/-qjKM6-nJ5vA/AAAAAAAAAAI/AAAAAAAAAEM/6QXLPvQFe1s/s64/photo.jpg","userId":"00421792487393303898"}},"outputId":"497ce04c-6a22-41a9-a39a-fb20a9d11813"},"source":["##YOUR CODE HERE\n","sevens"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R5o64GAh8WDp"},"source":["As we might expect, it's full of image files. Let’s take a look at one now. Here’s an image of a handwritten number 7, taken from the famous MNIST dataset of handwritten numbers:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":45},"id":"jetLpe078WDq","executionInfo":{"status":"ok","timestamp":1611225139198,"user_tz":-60,"elapsed":1221,"user":{"displayName":"Merlin Schäfer","photoUrl":"https://lh5.googleusercontent.com/-qjKM6-nJ5vA/AAAAAAAAAAI/AAAAAAAAAEM/6QXLPvQFe1s/s64/photo.jpg","userId":"00421792487393303898"}},"outputId":"7c37b712-c491-448d-82f3-2a65a9c027fd"},"source":["image_7_path = sevens[0]\n","image_7 = Image.open(image_7_path)\n","image_7"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LbKRTEBT8WDq"},"source":["Here we are using the `Image` class from the *Python Imaging Library* (PIL), which is the most widely used Python package for opening, manipulating, and viewing images. Jupyter knows about PIL images, so it displays the image for us automatically.\n","\n","In a computer, everything is represented as a number. To view the numbers that make up this image, we have to convert it to a *NumPy array* or a *PyTorch tensor*. For instance, here's what the image looks like, converted to a NumPy array:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lmT0453y8WDq","executionInfo":{"status":"ok","timestamp":1611225152688,"user_tz":-60,"elapsed":1271,"user":{"displayName":"Merlin Schäfer","photoUrl":"https://lh5.googleusercontent.com/-qjKM6-nJ5vA/AAAAAAAAAAI/AAAAAAAAAEM/6QXLPvQFe1s/s64/photo.jpg","userId":"00421792487393303898"}},"outputId":"a0b8a0bc-df78-4050-9c91-16efa8dd90f3"},"source":["np.array(image_7)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UiduSsWl8WDr"},"source":["You can see that the background white pixels are stored as the number 0, black is the number 255, and shades of gray are between the two. The entire image contains 28 pixels across and 28 pixels down, for a total of 784 pixels. (This is much smaller than an image that you would get from a phone camera, which has millions of pixels, but is a convenient size for our start in computer vision. From here it is not hard to build up to bigger, full-color images.)\n","\n","\n","\n","Our NN will work best with values between 0-1. One way to convert our image data into this format is by dividing the current values by 255. Numpy's array math makes this a quick and powerful operation."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OZrQLsxM8WDr","executionInfo":{"status":"ok","timestamp":1611225155956,"user_tz":-60,"elapsed":1276,"user":{"displayName":"Merlin Schäfer","photoUrl":"https://lh5.googleusercontent.com/-qjKM6-nJ5vA/AAAAAAAAAAI/AAAAAAAAAEM/6QXLPvQFe1s/s64/photo.jpg","userId":"00421792487393303898"}},"outputId":"3550f3bc-df7d-4509-acbd-8372dd92c8e7"},"source":["np.array(image_7)/255"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1Vml6-bl8WDr"},"source":["For some frameworks this step would be necessary and you'd have to perform it for the whole dataset before training.\n","fast.ai integrates this step in the dataloading process through the DataLoaders, so we won't do it manually here. But you may want to keep this in mind if you work with other frameworks.\n","\n","## Loading and preparing our data\n","\n","In our regression example you saw one possibility to load data.\n","Here we use a more general appraoch (although fast.ai provides one similiar to the TabularDataLoaders for images).\n","\n","We first create a DataBlock. We specify which blocks it contains; one holds our image data and one the categories/labels. We then tell our DataBlock how to retrieve the images, then how to split the data into training and validation split and finally how to get the labels. In our case it's relatively straightforward: The DataBlock gets the images from any path we pass to it later, it will randomly split the data 80/20 and get the label from the \"parent\" folder, so the folder that contains the image.\n","\n","If any of this is still not 100% clear, stick with us. It's normal, I too struggled with it the very first time I saw it  and if you want to understand it further ask in Slack, go to fast.ai or join the next AI track."]},{"cell_type":"code","metadata":{"id":"tFgyQJ5X8WDr","executionInfo":{"status":"ok","timestamp":1611225158598,"user_tz":-60,"elapsed":1222,"user":{"displayName":"Merlin Schäfer","photoUrl":"https://lh5.googleusercontent.com/-qjKM6-nJ5vA/AAAAAAAAAAI/AAAAAAAAAEM/6QXLPvQFe1s/s64/photo.jpg","userId":"00421792487393303898"}}},"source":["mnist = DataBlock(\n","        blocks=(ImageBlock, CategoryBlock), \n","        get_items=get_image_files, \n","        splitter=RandomSplitter(valid_pct = 0.2),\n","        get_y=parent_label)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2d5_Gh5HFslj"},"source":["Now that we have our DataBlock object we can load the data from the 'training' folder. We use `.dataloaders()` and pass it the path as well as `bs = 32` which is our batch size. That means for every step our optimizing algorithm takes to adjust the networks weights it will look at 32 examples from our data.\r\n","\r\n","#### NOW YOU\r\n","Think about why we might use only some pictures at every step and not the whole training set. (Hint: (Batch) Gradient Descent, Stochastic Gradient Descent, Mini-Batch Gradient Descent)\r\n","\r\n","\r\n","Go to the fast.ai documentation and find a way to load and prepare our data without specifying the DataBlock.\r\n"]},{"cell_type":"code","metadata":{"id":"d5djpSMt8WDr","executionInfo":{"status":"ok","timestamp":1611225174740,"user_tz":-60,"elapsed":14685,"user":{"displayName":"Merlin Schäfer","photoUrl":"https://lh5.googleusercontent.com/-qjKM6-nJ5vA/AAAAAAAAAAI/AAAAAAAAAEM/6QXLPvQFe1s/s64/photo.jpg","userId":"00421792487393303898"}}},"source":["dls = mnist.dataloaders(path/\"training\", bs = 32)\n","#dls = ImageDataLoaders.from_folder(path,train = \"training\", valid_pct=0.2, bs = 32, size = 28) #the short way going around the DataBlock"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mEWiCpsyGfR8"},"source":["#### NOW YOU\r\n","Use the method to show a batch (or part of it) to view the loaded images. This is a good way to check whether everything worked during the data loading and whether the data looks as expected."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":536},"id":"4h9xrBQz8WDs","executionInfo":{"status":"ok","timestamp":1611225175573,"user_tz":-60,"elapsed":5004,"user":{"displayName":"Merlin Schäfer","photoUrl":"https://lh5.googleusercontent.com/-qjKM6-nJ5vA/AAAAAAAAAAI/AAAAAAAAAEM/6QXLPvQFe1s/s64/photo.jpg","userId":"00421792487393303898"}},"outputId":"b6fb092c-5364-4585-92f0-1cb58aa50780"},"source":["##YOUR CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4YMkbBBnHLy7"},"source":["## Training the model\r\n","\r\n","#### NOW YOU\r\n","Fill in the code below with what you have learned in the regression example. The only thing set for you are the model and the `pretrained=` argument. You need to specify the dataloaders and metrics you want to use. You can pass multiple metreics, whatever metrics you use are calculated on the validation set and should include accuracy for our example. "]},{"cell_type":"code","metadata":{"id":"exzzXwyy8WDs","executionInfo":{"status":"ok","timestamp":1611225180089,"user_tz":-60,"elapsed":1393,"user":{"displayName":"Merlin Schäfer","photoUrl":"https://lh5.googleusercontent.com/-qjKM6-nJ5vA/AAAAAAAAAAI/AAAAAAAAAEM/6QXLPvQFe1s/s64/photo.jpg","userId":"00421792487393303898"}}},"source":["##YOUR CODE HERE (FILL THE BLANKS)\n","#______ = cnn_learner(___,resnet18,pretrained = False, _________________)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UbFYdDkk_OvB"},"source":["#### NOW YOU\r\n","Let's train our model. We will again use the one cycle method you've seen in our regression example. Train for 2 epochs. \r\n","\r\n","If you feel like this is taking very long (>5min per epoch) scroll down and learn what you can do about it."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":108},"id":"Qdx55Nac8WDs","executionInfo":{"status":"ok","timestamp":1611225460705,"user_tz":-60,"elapsed":278631,"user":{"displayName":"Merlin Schäfer","photoUrl":"https://lh5.googleusercontent.com/-qjKM6-nJ5vA/AAAAAAAAAAI/AAAAAAAAAEM/6QXLPvQFe1s/s64/photo.jpg","userId":"00421792487393303898"}},"outputId":"f511429c-fc3b-4c84-cabf-02c706b24428"},"source":["##YOUR CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YfBSSYQm9n1Q"},"source":["What you see above is the training process, as the model we are using is quite large it will take a while. But if we would wait for this long every time we trained a model on data as \"simple\" as 28x28 pixel black and white images we wouldn't get very far.\r\n","\r\n","This is were the GPU comes in. GPU stands for Graphics Processing Unit, sometimes referred to as Graphics Card ord Graphics Chip. You may know that many video games require such hardware. It turns out that the computations we need to train our model are similar to those needed to display high quality 3D graphics. Deep learning thus usually requires GPU's or even TPUs (a special Tensor Processing Unit made for deep learning and similar operations).\r\n","\r\n","Here in Google Colabs you can use a powerful GPU for free! \r\n","\r\n","*Note* Even if you have a Nvidia GPU on your local machine setting up the deep learning functionalities can be a little involved. We **highly** recommend you stick with Colabs first to learn about deep learning before you spend hours (potentially) to set up your local machine.\r\n","\r\n","To use a GPU go to 'Runtime', 'Change runtime type' and select the **GPU** as the Hardware accelerator. The notebook will reset and runtime will start again, which means you will have to start from the beginning. So keep in mind to select the GPU **before** you run the first lines of code in your next notebook.\r\n","\r\n","Now run the notebook again and hopefully you can experience a serious boost in performance.\r\n","\r\n","*Note* This performance boost applies to large neural networks, using a GPU might not benefit other ML algorithms in the same way."]},{"cell_type":"markdown","metadata":{"id":"AkcoAbijAcIV"},"source":["## That's a lot of accuracy for only \"seeing\" every image twice"]},{"cell_type":"markdown","metadata":{"id":"7qmKzrO4hX71"},"source":["Before we applaude our solution let's check our classifier on some unseen data from the test set.\r\n","\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":146},"id":"SHW0EB_Tixiu","executionInfo":{"status":"ok","timestamp":1611226804619,"user_tz":-60,"elapsed":1709,"user":{"displayName":"Merlin Schäfer","photoUrl":"https://lh5.googleusercontent.com/-qjKM6-nJ5vA/AAAAAAAAAAI/AAAAAAAAAEM/6QXLPvQFe1s/s64/photo.jpg","userId":"00421792487393303898"}},"outputId":"7f0247f7-dd9c-4eed-dc0c-6c73e120db66"},"source":["test_img_path = [dir.ls()[0] for dir in (path/\"testing\").ls()] #creates a list of file paths for our testing images\r\n","test_img = [PILImage.create(img_path) for img_path in test_img_path] #creates testing images from the paths we can display and predict\r\n","test_preds = [learner.predict(img)[0] for img in test_img] #creates predictions\r\n","\r\n","print(\"Predictions:\")\r\n","ipyplot.plot_images(test_img,test_preds, max_images=10, img_width=28)\r\n","print(\"TestImages:\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r79Nd89NAnd3"},"source":["As you can see we reach very high accuracy on the validation set with just two epochs. \r\n","\r\n","The MNIST dataset is pretty \"easy\" for a large neural network that was build for image classification such as resnet18. (BTW if you think 18 layers is deep, check out resnet50 or resnet152)\r\n","\r\n","So let's check out how it does on images that are a little larger,more colorful and a little more diverse."]},{"cell_type":"markdown","metadata":{"id":"40G5i0flCtSm"},"source":["Head to the next notebook to use your knowledge on harder image classification problems. Remember, GPUs and experimentation are your friends."]},{"cell_type":"code","metadata":{"id":"xxQZmllGhM9Z"},"source":[],"execution_count":null,"outputs":[]}]}